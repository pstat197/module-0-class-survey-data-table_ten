---
title: "Analysis of Class Surveys"
subtitle: "PSTAT 197A Module 0"
author: "Adarsh Nagar, Brooks Piper, Srinidhi Sathish, Nicole Xu, Nini Yen"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

```{r}
# load any other packages and read data here
library(tidyverse)
library(ggplot2)
library(dplyr)
library(scales)
library(corrr)
library(janitor)
library(nnet)

background <- read_csv('../data/background-clean.csv')
interest <- read_csv('../data/interest-clean.csv')

all_data <- background %>% inner_join(interest, by = join_by(response_id)) %>% rename(c(domain_yn = dom.x, domain_type = dom.y, research_or_industry = do_you_have_any_preference_regarding_working_on_an_industry_project_or_a_research_lab_project))

all_data$lang[all_data$response_id == 29] <- "Python"
```

## Executive summary

Write a one-paragraph abstract summarizing what you did and your findings. It need not be comprehensive; try to highlight the most important or interesting outcomes.

## Data description

-   **Source:** Survey distributed to all students offered enrollment in **PSTAT197A, Fall 2025**.

-   **Sample Size:** 𝑛 = 60 responses.

-   **Sampling:** No random selection. Can be considered:

    -   A census of PSTAT197A enrollees, or

    -   A convenience sample of students interested in **data science/capstones**.

**Sample Characteristics:**

| Characteristic       | Count | Percent |
|----------------------|-------|---------|
| **Class Standing**   |       |         |
| Junior               | 9     | 15%     |
| Senior               | 51    | 85%     |
| **Gender Identity**  |       |         |
| Female               | 28    | 46.7%   |
| Male                 | 32    | 53.3%   |
| **Race / Ethnicity** |       |         |
| Asian                | 43    | 71.7%   |
| Caucasian            | 13    | 21.7%   |
| Multiracial          | 3     | 5%      |
| Prefer not to say    | 1     | 1.7%    |

**Consent for sharing:**

| Share background | Share project preferences | Count |
|------------------|---------------------------|-------|
| Yes              | Yes                       | 49    |
| Yes              | No                        | 2     |
| No               | Yes                       | 3     |
| No               | No                        | 6     |

**Measurements Collected:**

-   **Self-reported proficiency** in programming, math, and statistics: `beg`, `int`, `adv`.

-   **Comfort levels** (numeric scale 1–5) in programming (`prog.comf`), math (`math.comf`), statistics (`stat.comf`).

-   **Course history:** Counts of courses taken in departments like PSTAT, CS, LING, ECON.

-   **Past research experience**, project preferences, and demographic info.

**Notes on the dataset:**

-   Personal information, free-text responses, and students who did not consent were removed.

-   Some variables, like distinctions in research experiences, were simplified for analysis.

**Summary Statistics:**

| Variable  | Mean | Median | Min | Max |
|-----------|------|--------|-----|-----|
| prog.comf | 3.86 | 4      | 2   | 5   |
| math.comf | 4.04 | 4      | 3   | 5   |
| stat.comf | 4.04 | 4      | 2   | 5   |

-   Proficiency levels (numeric) roughly align with comfort ratings:

    -   `prog`: 2.9 (mean)

    -   `math`: 2.78

    -   `stat`: 2.83

## Questions of interest

Indicate the questions your analysis addresses. These should map one-to-one to your findings. Don't include questions you didn't answer or questions you started with and refined later. If you would rather frame them as goals or tasks rather than questions that is okay; just modify the header appropriately. However you frame what you've done, you may only have two or three items; that is fine. Provide an itemized or numbered list so that the reader can easily identify your objectives.

We sought to understand how students’ programming language preferences relate to their academic background, skills, and project interests.In particular, we examined whether language preference aligns with coursework patterns in different departments, students’ domain interests, project type preferences (industry vs. research), class level or standing, and overall academic background. Our analysis addressed the following questions:

1.  How does students’ academic background and preparation relate to their programming language preference?

2.  How do students’ programming language preferences influence their interests and coursework choices?

3.  Does a student’s preferred programming language (R, Python, or no preference) influence their self-reported proficiency and comfort in programming and math? 

## Findings

### Language and Proficiency

The following analyses examine how students’ programming language preference (R, Python, or No preference) relates to their proficiency and comfort in programming and math.

**Comfort and Proficiency by Language**

We first converted students’ self-reported proficiency levels in programming and math into numeric scores (1 = beginner, 2 = intermediate, 3 = advanced) and combined them with their comfort scores. The table below shows the ANOVA results testing for differences in these scores by language preference:

```{r}
# Only select needed columns
prof_data <- all_data %>%
  select(lang, prog.prof, prog.comf, math.prof, math.comf)

# Turn text proficiency levels into numbers
prof_data <- prof_data %>%
  mutate(
    prog.prof.num = recode(prog.prof, "beg" = 1, "int" = 2, "adv" = 3
    ),
    math.prof.num = recode(math.prof, "beg" = 1, "int" = 2, "adv" = 3
    )
  )

# Pivot longer
prof_data_long <- prof_data %>%
  pivot_longer(
    cols = c(prog.prof.num, prog.comf, math.prof.num, math.comf),
    names_to = "skill_type",
    values_to = "score"
  ) %>%
  mutate(
    skill_type = recode(skill_type,
                        "prog.prof.num" = "Programming Proficiency",
                        "prog.comf" = "Programming Comfort",
                        "math.prof.num" = "Math Proficiency",
                        "math.comf" = "Math Comfort")
  )

# Run ANOVA: Does comfort/proficiency differ by language?
prof_anova_result <- aov(score ~ lang * skill_type, data = prof_data_long)
summary(prof_anova_result)
```

The ANOVA indicates that **there is a significant difference between skill types** (Programming vs Math, Proficiency vs Comfort), but **no significant differences between languages** or their interaction with skill type. In other words, students’ comfort and proficiency levels are fairly similar across those preferring R, Python, or having no preference.

**Visualization**

The boxplot below illustrates the distributions of programming and math comfort and proficiency scores by language preference:

```{r}
# Visualize mean differences
ggplot(prof_data_long, aes(x = lang, y = score, fill = skill_type)) +
  geom_boxplot() +
  labs(
    title = "Comfort and Proficiency by Language Preference",
    x = "Language Preference",
    y = "Score (1–5 scale or recoded proficiency)",
    fill = "Skill Type"
  ) +
  theme_minimal()
```

From the plot, we see that **median scores are similar across language preferences** for both programming and math. Programming proficiency and comfort are slightly higher on average than math scores, consistent with the overall skill distribution in the class. The following chart displays the distribution of students that prefer each programming language in the class. As shown, a majority of students (around 60%) prefer Python, around 22% of students are not partial toward either language, and around 18% of the class prefers R.

### Language and Project Preferences

```{r}
lang_summary <- all_data %>%
  count(lang) %>%
  mutate(prop = n / sum(n)) %>%
  arrange(desc(prop))

## Bar Chart Of Language Preference w/ Percents

ggplot(lang_summary, aes(x = reorder(lang, -prop), y = prop, fill = lang)) +
  geom_col() +
  geom_text(aes(label = scales::percent(prop, accuracy = 0.1)), 
            vjust = -0.5, size = 4) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Proportions of Language Preference",
    x = "Preferred Language",
    y = "Percentage"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

The bar chart below illustrates the relationship between students’ project type preferences and their preferred programming language. The figure shows that a majority of those who prefer Python (79%) prefer to work on an industry-sponsored project, whereas a majority of students that prefer R either do not prefer one type of project over another. This may be due to the fact that Python is more prevalent in the industry, so students who prefer Python are more likely to seek industry-sponsored projects rather that research-based projects, which tend to use R.

```{r}
plot_data <- all_data %>%
  count(lang, type) %>%
  group_by(lang) %>%
  mutate(prop = n / sum(n))

# Distribution of those who prefer each type of Project
# By Language Preference
ggplot(plot_data, aes(x = lang, y = prop, fill = type)) +
  geom_col(position = "fill") +
  geom_text(
    aes(label = percent(prop, accuracy = 1)),
    position = position_fill(vjust = 0.5),
    size = 4
  ) +
  labs(
    title = "Project Type Preference by Language Preference",
    x = "Preferred Language",
    y = "Proportion",
    fill = "Project Type Preference"
  ) +
  scale_y_continuous(labels = percent) +
  theme_minimal()

```

### Language and Coursework

The following chart shows that programming language preference is associated with coursework patterns. Students preferring R have taken more PSTAT courses (5.22 average) compared to Python-preferring students (4.55), showing more PSTAT coursework and experience is correlated with R preference. Conversely, Python-preferring students have completed more CS courses (1.52 vs. 1.11), aligning with Python's prominence in computer science. ECON and LING courses show less variation across language preferences, suggesting they don't heavily influence language choice. Overall, the data indicates that students' language preferences reflect their disciplinary preparation.

```{r}
# course groups from list
course_cols <- c("PSTAT100", "PSTAT115", "PSTAT120", "PSTAT122", "PSTAT126", 
                 "PSTAT131", "PSTAT160", "PSTAT174", "CS9", "CS16", "LING104", 
                 "LING110", "LING111", "CS130", "CS165", "ECON145", "PSTAT127", 
                 "PSTAT134", "CS5")

pstat_courses <- c("PSTAT100", "PSTAT115", "PSTAT120", "PSTAT122", "PSTAT126", 
                   "PSTAT131", "PSTAT160", "PSTAT174", "PSTAT127", "PSTAT134")
cs_courses <- c("CS9", "CS16", "CS130", "CS165", "CS5")
ling_courses <- c("LING104", "LING110", "LING111")
econ_courses <- c("ECON145")

# average number of courses taken by language preference
# more CS courses -> Python
# more PSTAT, Ling --> R

course_averages <- all_data %>%
  filter(lang %in% c("R", "Python", "No preference")) %>%
  mutate(
    pstat_total = rowSums(select(., all_of(pstat_courses)), na.rm = TRUE),
    cs_total = rowSums(select(., all_of(cs_courses)), na.rm = TRUE),
    ling_total = rowSums(select(., all_of(ling_courses)), na.rm = TRUE),
    econ_total = rowSums(select(., all_of(econ_courses)), na.rm = TRUE)
  ) %>%
  group_by(lang) %>%
  summarise(
    n = n(),
    avg_pstat = mean(pstat_total, na.rm = TRUE),
    avg_cs = mean(cs_total, na.rm = TRUE),
    avg_ling = mean(ling_total, na.rm = TRUE),
    avg_econ = mean(econ_total, na.rm = TRUE),
    avg_total = mean(pstat_total + cs_total + ling_total + econ_total, na.rm = TRUE)
  )

course_avg_long <- course_averages %>%
  select(lang, avg_pstat, avg_cs, avg_ling, avg_econ) %>%
  pivot_longer(cols = starts_with("avg_"), 
               names_to = "course_type", 
               values_to = "avg_courses") %>%
  mutate(course_type = case_when(
    course_type == "avg_pstat" ~ "PSTAT",
    course_type == "avg_cs" ~ "CS",
    course_type == "avg_ling" ~ "LING",
    course_type == "avg_econ" ~ "ECON"
  ))

ggplot(course_avg_long, aes(x = course_type, y = avg_courses, fill = lang)) +
  geom_col(position = "dodge") +
  geom_text(
    aes(label = round(avg_courses, 2)),
    position = position_dodge(width = 0.9),
    vjust = -0.5,
    size = 3.5
  ) +
  labs(
    title = "Average Number of Courses Taken by Language Preference",
    x = "Course Department",
    y = "Average Number of Courses",
    fill = "Language Preference"
  ) +
  theme_minimal() +
  theme(legend.position = "top")
```

### Language and Data Science Interests

Next we examine what areas of data science each language preference group is interested in. We start by separating out each of the possible areas through one-hot encoding so we can take a look at some of the patterns of area interest between the language groups.

```{r}
ds_interest_data <- all_data %>% select(c(lang, area)) %>% mutate(area_image = ifelse(str_detect(area, "Analysis or classification of images"), 1, 0),
                                area_dlnn = ifelse(str_detect(area, "Deep learning and neural networks"), 1, 0),
                                area_spatial = ifelse(str_detect(area, "Spatial statistics or time series analysis"), 1, 0),
                                area_dataeng = ifelse(str_detect(area, "Data acquisition and engineering"), 1, 0),
                                area_nlp = ifelse(str_detect(area, "Natural language processing and analysis of text"), 1, 0),
                                area_software = ifelse(str_detect(area, "Model deployment and software or web integrations"), 1, 0),
                                area_vis = ifelse(str_detect(area, "Data visualization and interactive dashboards"), 1, 0),
                                area_pred = ifelse(str_detect(area, "Predictive modeling, generally"), 1, 0),
                                area_stat = ifelse(str_detect(area, "Statistical models and inference, generally"), 1, 0),
                                area_database = ifelse(str_detect(area, "Databases"), 1, 0),
                                area_algo = ifelse(str_detect(area, "Algorithms"), 1, 0)) %>% select(-area)
```

```{r}
ds_interest_data %>%
  pivot_longer(starts_with("area_"), names_to = "Area", values_to = "Interested") %>%
  group_by(Area, lang) %>%
  summarise(n = sum(Interested), .groups = "drop") %>%
  group_by(Area) %>%
  mutate(Percent = n / sum(n)) %>%
  ggplot(aes(x = lang, y = Area, fill = Percent)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Preference by Data Science Interest Area", x = "Preference", y = "Interest Area")
```
As we've already found, there is an overall preference for Python over R. Those that prefer Python have the most interest in natural language processing and software engineering. Meanwhile those that prefer R appear to be more interested in statistical models and inference, predictive modeling, and image classification. Students with no preference show the most interest in data visualization and spatial statistics/time series.

In the table below, we can also take a look at whether or not there are correlations between the different areas of data science interest. We see for example, that an interest in algorithms is fairly positively correlated with an interest in natural language processing. On the other hand, an interest in algorithms is a little negatively correlated with an interest in deep learning and neural networks. Overall, there are some slight correlations between all the areas of interest, which makes sense as they all fall under a general interest in data science.

```{r message=F}
ds_interest_data %>%
  select(starts_with("area_")) %>%
  correlate() %>% knitr::kable()
```

Next, we were interested in seeing if a students' data science areas of interest could inform their language preferences. Thus we fitted a multinomial regression:
```{r}
model_mn <- multinom(lang ~ ., data = ds_interest_data)

(summary(model_mn))
```
```{r message=F}
model_null <- multinom(lang ~ 1, data = ds_interest_data)
anova(model_null, model_mn, test = "Chisq")
```
Looking at the model outputs, with language preference (R, Python, or No Preference) as a function of research interests using multinomial logistic regression and using “No Preference” as the reference category, we find that coefficients suggest that interest in Deep Learning/Neural Networks (`area_dlnn`) is associated with higher odds of preferring Python, while interest in statistical methods (`area_stat`) appears to slightly increase the odds of preferring R. However, a likelihood ratio test comparing the full model to the null model (intercept only) indicated that the overall model does not significantly improve fit over the null (p = 0.18). Thus, while some trends are visible, there is no strong statistical evidence that research interests collectively predict language preference in this dataset. This may be because the dataset is underpowered due to the small sample size.


## Useful tips (remove this section)

Due to the visual editor, most common needs for authoring can be met using menu items in the RStudio IDE. For a comprehensive guide to Quarto, see the [documentation](https://quarto.org/docs/guide/); consult the documentation for anything you can't sort out in the IDE.

### Code chunks

Insert code chunks using the *Insert* drop-down menu or `ctrl + alt + I` . By default in this document, codes will not be shown but results will. If you want to change this behavior, add the chunk option `echo: true` as below.

```{r}
#| echo: true
my_df <- tibble(animal = c('snake', 'gecko'),
                threatening = c(TRUE, FALSE))

my_df
```

Code chunks will be executed in order when the document is rendered, so packages should be loaded at the very beginning of the document

### Rendering tables in markdown

Several functions exist for converting dataframes to markdown tables for nice display. A simple one from the `knitr` package is `knitr::kable()` .

```{r}
my_df %>% knitr::kable()
```

### Figures

To include any figures not generated by code chunks, use *Insert \> Figure / Image* or `![CAPTION](path/file.ext)` .

Most of the time code chunks producing plots will render fine. However, to adjust sizing or alignment, use the chunk options `fig-width` and `fig-height` . Captions can be added with `fig-cap` .

```{r}
#| fig-width: 4
#| fig-height: 3
#| fig-align: left
#| fig-cap: A terrible plot.

my_df %>% 
  ggplot(aes(x = animal, y = threatening)) + 
  geom_col()
```

### Links

To include any hyperlinks, use `[display text](url)` .
